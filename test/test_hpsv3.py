# from hpsv3 import HPSv3RewardInferencer

# # Initialize the model
# inferencer = HPSv3RewardInferencer(device='cuda')

# # Evaluate images
image_paths = ["/mnt/workspace/user/zengdawei.zdw/shared/jinghan.zq/DiffusionRL/visual_results/flux-dev.png", "/mnt/workspace/user/zengdawei.zdw/shared/jinghan.zq/DiffusionRL/visual_results/flux-dev.png"]
prompts = [
  "A orange cat is holding a card with hello world written on it",
  "A orange cat is holding a card with hello world written on it"
]

# # Get preference scores
# rewards = inferencer.reward(image_paths, prompts)
# scores = [reward[0].item() for reward in rewards]  # Extract mu values
# print(f"Image scores: {scores}")

import hpsv2

# imgs_path can be a list of image paths, with the images generated by the same prompt
# or image path of string type
# or image of PIL.Image.Image type
# result = hpsv2.score(image_paths[0], prompts[0], hps_version="v2.1") 

import torch
from hpsv2.src.open_clip import create_model_and_transforms, get_tokenizer
from typing import Union
import huggingface_hub
from hpsv2.utils import root_path, hps_version_map

torch.cuda.set_device(0)
device = torch.cuda.current_device()

def initialize_model():
    model_dict = {}
    model, preprocess_train, preprocess_val = create_model_and_transforms(
        'ViT-H-14',
        '/mnt/workspace/user/zengdawei.zdw/shared/jinghan.zq/DanceGRPO/hps_ckpt/models--laion--CLIP-ViT-H-14-laion2B-s32B-b79K/snapshots/1c2b8495b28150b8a4922ee1c8edee224c284c0c/open_clip_pytorch_model.bin',
        precision='amp',
        device=device,
        jit=False,
        force_quick_gelu=False,
        force_custom_text=False,
        force_patch_dropout=False,
        force_image_size=None,
        pretrained_image=False,
        image_mean=None,
        image_std=None,
        light_augmentation=True,
        aug_cfg={},
        output_dict=True,
        with_score_predictor=False,
        with_region_predictor=False
    )
    model_dict['model'] = model
    model_dict['preprocess_val'] = preprocess_val
    return model_dict
model_dict = initialize_model()
model = model_dict['model']
preprocess_val = model_dict['preprocess_val']
#cp = huggingface_hub.hf_hub_download("xswu/HPSv2", hps_version_map["v2.1"])
cp = "/mnt/workspace/user/zengdawei.zdw/shared/jinghan.zq/DanceGRPO/hps_ckpt/models--xswu--HPSv2/snapshots/697403c78157020a1ae59d23f111aa58ced35b0a/HPS_v2.1_compressed.pt"

checkpoint = torch.load(cp, map_location=f'cuda:{device}')
model.load_state_dict(checkpoint['state_dict'])
processor = get_tokenizer('ViT-H-14')
reward_model = model.to(device)
reward_model.eval()