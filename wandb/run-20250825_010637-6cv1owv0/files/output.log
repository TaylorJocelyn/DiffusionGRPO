***** Running training *****
08/25/2025 01:06:39 - INFO - utils.data_utils -   ***** Running training *****
  Num examples = 11995
08/25/2025 01:06:39 - INFO - utils.data_utils -     Num examples = 11995
  Dataloader size = 1500
08/25/2025 01:06:39 - INFO - utils.data_utils -     Dataloader size = 1500
  Resume training from step 0
08/25/2025 01:06:39 - INFO - utils.data_utils -     Resume training from step 0
  Instantaneous batch size per device = 1
08/25/2025 01:06:39 - INFO - utils.data_utils -     Instantaneous batch size per device = 1
  Total train batch size (w. data & sequence parallel, accumulation) = 32.0
08/25/2025 01:06:39 - INFO - utils.data_utils -     Total train batch size (w. data & sequence parallel, accumulation) = 32.0
  Gradient Accumulation steps = 4
08/25/2025 01:06:39 - INFO - utils.data_utils -     Gradient Accumulation steps = 4
  Total optimization steps per epoch = 300
08/25/2025 01:06:39 - INFO - utils.data_utils -     Total optimization steps per epoch = 300
  Total training parameters per FSDP shard = 1.491297992 B
08/25/2025 01:06:39 - INFO - utils.data_utils -     Total training parameters per FSDP shard = 1.491297992 B
  Master weight dtype: torch.bfloat16
08/25/2025 01:06:39 - INFO - utils.data_utils -     Master weight dtype: torch.bfloat16
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:17<00:00,  1.10s/it]
08/25/2025 01:06:57 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:17<00:00,  1.52it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.53it/s]
08/25/2025 01:07:09 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.53it/s]
08/25/2025 01:07:20 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.53it/s]
08/25/2025 01:07:31 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
--> decode image and save to log dir...
gathered_reward {'ctr_reward': [], 'ecp_reward': [], 't2i_reward': [], 'hps_reward': tensor([0.0682, 0.0703, 0.0709, 0.0691, 0.0233, 0.0217, 0.0273, 0.0265, 0.0626,
        0.0587, 0.0579, 0.0563, 0.0256, 0.0246, 0.0237, 0.0278, 0.0771, 0.0797,
        0.0796, 0.0760, 0.0210, 0.0191, 0.0198, 0.0181, 0.0749, 0.0777, 0.0779,
        0.0783, 0.0776, 0.0764, 0.0772, 0.0825], device='cuda:0')}
len samples_batched_list:  4
idx i:  0
ratio: 1.00
08/25/2025 01:07:59 - INFO - utils.data_utils -   ratio: 1.00
advantage -1.1864
08/25/2025 01:07:59 - INFO - utils.data_utils -   advantage -1.1864
final loss: 0.0330
08/25/2025 01:07:59 - INFO - utils.data_utils -   final loss: 0.0330
idx i:  1
ratio: 1.00
08/25/2025 01:08:25 - INFO - utils.data_utils -   ratio: 1.00
advantage 0.5806
08/25/2025 01:08:25 - INFO - utils.data_utils -   advantage 0.5806
final loss: -0.0161
08/25/2025 01:08:25 - INFO - utils.data_utils -   final loss: -0.0161
idx i:  2
ratio: 1.00
08/25/2025 01:08:50 - INFO - utils.data_utils -   ratio: 1.00
advantage 1.0350
08/25/2025 01:08:50 - INFO - utils.data_utils -   advantage 1.0350
final loss: -0.0287
08/25/2025 01:08:50 - INFO - utils.data_utils -   final loss: -0.0287
idx i:  3
grad_norm_
ratio: 1.00
08/25/2025 01:09:16 - INFO - utils.data_utils -   ratio: 1.00
advantage -0.4291
08/25/2025 01:09:16 - INFO - utils.data_utils -   advantage -0.4291
final loss: 0.0119
08/25/2025 01:09:16 - INFO - utils.data_utils -   final loss: 0.0119
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
08/25/2025 01:09:27 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.55it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
08/25/2025 01:09:38 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.55it/s]
--> decode image and save to log dir...
Sampling Progress:  38%|████████████████████████████████████████████████▍                                                                                | 6/16 [00:04<00:07,  1.42it/s]
Traceback (most recent call last):██████████████████████████████████████▍                                                                                | 6/16 [00:03<00:06,  1.54it/s]
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1446, in <module>
    main(args)
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1092, in main
    loss, grad_norm = train_one_step(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 712, in train_one_step
    rewards, all_latents, all_log_probs, sigma_schedule, all_image_ids, all_condition_latents, all_condition_ids, all_condition_type_ids = sample_reference_model(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 541, in sample_reference_model
    z, latents, batch_latents, batch_log_probs, batch_condition_latents, batch_condition_ids, batch_condition_type_ids = run_sample_step(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 378, in run_sample_step
    pred = transformer(
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 864, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/transformers/transformer_flux.py", line 565, in forward
    hidden_states = block(
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 850, in forward
    args, kwargs = _pre_forward(
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 382, in _pre_forward
    unshard_fn(state, handle)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 417, in _pre_forward_unshard
    _unshard(state, handle, state._unshard_stream, state._pre_unshard_stream)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 299, in _unshard
    event.synchronize()
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/cuda/streams.py", line 224, in synchronize
    super().synchronize()
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1446, in <module>
[rank0]:     main(args)
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1092, in main
[rank0]:     loss, grad_norm = train_one_step(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 712, in train_one_step
[rank0]:     rewards, all_latents, all_log_probs, sigma_schedule, all_image_ids, all_condition_latents, all_condition_ids, all_condition_type_ids = sample_reference_model(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 541, in sample_reference_model
[rank0]:     z, latents, batch_latents, batch_log_probs, batch_condition_latents, batch_condition_ids, batch_condition_type_ids = run_sample_step(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 378, in run_sample_step
[rank0]:     pred = transformer(
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 864, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/transformers/transformer_flux.py", line 565, in forward
[rank0]:     hidden_states = block(
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 850, in forward
[rank0]:     args, kwargs = _pre_forward(
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 382, in _pre_forward
[rank0]:     unshard_fn(state, handle)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 417, in _pre_forward_unshard
[rank0]:     _unshard(state, handle, state._unshard_stream, state._pre_unshard_stream)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 299, in _unshard
[rank0]:     event.synchronize()
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/cuda/streams.py", line 224, in synchronize
[rank0]:     super().synchronize()
[rank0]: KeyboardInterrupt
