***** Running training *****
09/01/2025 21:04:15 - INFO - utils.data_utils -   ***** Running training *****
  Num examples = 11995
09/01/2025 21:04:15 - INFO - utils.data_utils -     Num examples = 11995
  Dataloader size = 2000
09/01/2025 21:04:15 - INFO - utils.data_utils -     Dataloader size = 2000
  Resume training from step 0
09/01/2025 21:04:15 - INFO - utils.data_utils -     Resume training from step 0
  Instantaneous batch size per device = 1
09/01/2025 21:04:15 - INFO - utils.data_utils -     Instantaneous batch size per device = 1
  Total train batch size (w. data & sequence parallel, accumulation) = 24.0
09/01/2025 21:04:15 - INFO - utils.data_utils -     Total train batch size (w. data & sequence parallel, accumulation) = 24.0
  Gradient Accumulation steps = 4
09/01/2025 21:04:15 - INFO - utils.data_utils -     Gradient Accumulation steps = 4
  Total optimization steps per epoch = 300
09/01/2025 21:04:15 - INFO - utils.data_utils -     Total optimization steps per epoch = 300
  Total training parameters per FSDP shard = 11.930383936 B
09/01/2025 21:04:15 - INFO - utils.data_utils -     Total training parameters per FSDP shard = 11.930383936 B
  Master weight dtype: torch.bfloat16
09/01/2025 21:04:15 - INFO - utils.data_utils -     Master weight dtype: torch.bfloat16
Steps:   0%|                                                                                                                                                 | 0/100000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1536, in <module>                                                                           | 0/16 [00:00<?, ?it/s]
    main(args)
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1182, in main
    loss, grad_norm = train_one_step(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 789, in train_one_step
    rewards, all_latents, all_log_probs, sigma_schedule, all_image_ids, all_condition_latents, all_condition_ids, all_condition_type_ids = sample_reference_model(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 618, in sample_reference_model
    z, latents, batch_latents, batch_log_probs, batch_condition_latents, batch_condition_ids, batch_condition_type_ids = run_sample_step(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 393, in run_sample_step
    cond_latents, cond_ids = encode_cond_images(
  File "/root/autodl-tmp/DiffusionGRPO/src/flux/pipeline_tools.py", line 130, in encode_cond_images
    images = vae.encode(images).latent_dist.sample()
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 282, in encode
    h = self._encode(x)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 256, in _encode
    enc = self.encoder(x)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/autoencoders/vae.py", line 156, in forward
    sample = self.conv_in(sample)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Input type (CPUBFloat16Type) and weight type (CUDABFloat16Type) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
[rank0]: Traceback (most recent call last):
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1536, in <module>
[rank0]:     main(args)
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1182, in main
[rank0]:     loss, grad_norm = train_one_step(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 789, in train_one_step
[rank0]:     rewards, all_latents, all_log_probs, sigma_schedule, all_image_ids, all_condition_latents, all_condition_ids, all_condition_type_ids = sample_reference_model(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 618, in sample_reference_model
[rank0]:     z, latents, batch_latents, batch_log_probs, batch_condition_latents, batch_condition_ids, batch_condition_type_ids = run_sample_step(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 393, in run_sample_step
[rank0]:     cond_latents, cond_ids = encode_cond_images(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/flux/pipeline_tools.py", line 130, in encode_cond_images
[rank0]:     images = vae.encode(images).latent_dist.sample()
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
[rank0]:     return method(self, *args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 282, in encode
[rank0]:     h = self._encode(x)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py", line 256, in _encode
[rank0]:     enc = self.encoder(x)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/diffusers/models/autoencoders/vae.py", line 156, in forward
[rank0]:     sample = self.conv_in(sample)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 554, in forward
[rank0]:     return self._conv_forward(input, self.weight, self.bias)
[rank0]:   File "/root/miniconda3/envs/aigc_rl/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
[rank0]:     return F.conv2d(
[rank0]: RuntimeError: Input type (CPUBFloat16Type) and weight type (CUDABFloat16Type) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
