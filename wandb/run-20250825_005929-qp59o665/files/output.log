***** Running training *****
08/25/2025 00:59:30 - INFO - utils.data_utils -   ***** Running training *****
  Num examples = 11995
08/25/2025 00:59:30 - INFO - utils.data_utils -     Num examples = 11995
  Dataloader size = 1500
08/25/2025 00:59:30 - INFO - utils.data_utils -     Dataloader size = 1500
  Resume training from step 0
08/25/2025 00:59:30 - INFO - utils.data_utils -     Resume training from step 0
  Instantaneous batch size per device = 1
08/25/2025 00:59:30 - INFO - utils.data_utils -     Instantaneous batch size per device = 1
  Total train batch size (w. data & sequence parallel, accumulation) = 32.0
08/25/2025 00:59:30 - INFO - utils.data_utils -     Total train batch size (w. data & sequence parallel, accumulation) = 32.0
  Gradient Accumulation steps = 4
08/25/2025 00:59:30 - INFO - utils.data_utils -     Gradient Accumulation steps = 4
  Total optimization steps per epoch = 300
08/25/2025 00:59:30 - INFO - utils.data_utils -     Total optimization steps per epoch = 300
  Total training parameters per FSDP shard = 1.491297992 B
08/25/2025 00:59:30 - INFO - utils.data_utils -     Total training parameters per FSDP shard = 1.491297992 B
  Master weight dtype: torch.bfloat16
08/25/2025 00:59:30 - INFO - utils.data_utils -     Master weight dtype: torch.bfloat16
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:22<00:00,  1.43s/it]
08/25/2025 00:59:54 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:22<00:00,  1.50it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.59it/s]
08/25/2025 01:00:05 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.58it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.53it/s]
08/25/2025 01:00:16 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
--> decode image and save to log dir...
Sampling Progress: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.53it/s]
08/25/2025 01:00:27 - INFO - utils.data_utils -   --> decode image and save to log dir...███████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.54it/s]
--> decode image and save to log dir...
gathered_reward {'ctr_reward': [], 'ecp_reward': [], 't2i_reward': [], 'hps_reward': tensor([0.0682, 0.0703, 0.0709, 0.0691, 0.0233, 0.0217, 0.0273, 0.0265, 0.0626,
        0.0587, 0.0579, 0.0563, 0.0256, 0.0246, 0.0237, 0.0278, 0.0771, 0.0797,
        0.0796, 0.0760, 0.0210, 0.0191, 0.0198, 0.0181, 0.0749, 0.0777, 0.0779,
        0.0783, 0.0776, 0.0764, 0.0772, 0.0825], device='cuda:0')}
err:  'dict' object has no attribute 'unsqueeze'
k  advantages
len samples_batched_list:  4
sample  {'timesteps': tensor([[ 300, 1000,  978,  868,  750,  833,  900,  576,  700,  409,  642,  928,
          794,  954,  500]], device='cuda:0'), 'latents': tensor([[[[ 0.3710,  1.4087,  0.3115,  ..., -0.3239, -0.7585, -2.0720],
          [-0.0664,  0.2575,  0.1918,  ..., -0.9126,  0.1306, -1.0645],
          [-0.7450,  0.3663,  0.1560,  ..., -0.3358, -0.4574, -1.0435],
          ...,
          [ 0.8136,  0.2420,  0.0844,  ..., -0.2773, -1.1860, -0.0608],
          [ 0.6445,  0.0274,  0.7323,  ..., -0.7965, -0.0986, -0.3813],
          [ 0.4522,  0.0652,  1.2267,  ..., -1.3712, -0.2240, -0.5334]],

         [[ 0.1943,  2.1562,  0.0232,  ...,  0.1670,  0.2451, -3.1406],
          [-0.1719,  0.8477, -0.7500,  ..., -1.3984,  0.9062, -0.9375],
          [-1.9219,  0.6523, -0.5469,  ..., -0.1484, -0.7188, -1.7031],
          ...,
          [ 1.3984,  0.0334, -0.0938,  ...,  0.0055, -1.7188,  1.1016],
          [ 0.6914, -0.6719,  1.5859,  ..., -1.7031,  1.1172,  0.8516],
          [ 0.8438, -0.4102,  1.5938,  ..., -2.1094,  0.9297,  0.5781]],

         [[ 0.1528,  2.1250,  0.0403,  ...,  0.2182,  0.1919, -3.0349],
          [-0.1685,  0.8578, -0.7008,  ..., -1.3787,  0.8812, -0.8446],
          [-1.8650,  0.6566, -0.4611,  ..., -0.1353, -0.6820, -1.6257],
          ...,
          [ 1.3464, -0.0157, -0.1057,  ...,  0.0083, -1.6834,  1.1149],
          [ 0.7052, -0.6253,  1.5157,  ..., -1.6735,  1.0792,  0.8521],
          [ 0.8007, -0.4364,  1.6168,  ..., -2.0444,  0.9834,  0.5041]],

         ...,

         [[ 0.2599,  1.9024,  0.1984,  ...,  0.0338,  0.0061, -2.9104],
          [-0.0665,  0.6730, -0.1857,  ..., -1.3691,  0.6855, -0.8217],
          [-1.4226,  0.6242, -0.3675,  ..., -0.2469, -0.5578, -1.3708],
          ...,
          [ 1.3454,  0.2029,  0.0256,  ...,  0.0247, -1.4978,  0.6549],
          [ 0.6381, -0.4432,  1.2994,  ..., -1.4073,  0.6185,  0.6508],
          [ 0.7975, -0.0930,  1.6462,  ..., -1.8246,  0.5845,  0.1275]],

         [[ 0.2350,  2.0688,  0.0970,  ...,  0.2158,  0.2495, -2.9093],
          [-0.2127,  0.8057, -0.6211,  ..., -1.3435,  0.8837, -0.8254],
          [-1.8323,  0.6708, -0.4005,  ..., -0.2597, -0.6627, -1.5818],
          ...,
          [ 1.3695,  0.0187, -0.1004,  ...,  0.0169, -1.6307,  1.0316],
          [ 0.7552, -0.5190,  1.5085,  ..., -1.6485,  1.0266,  0.8439],
          [ 0.7919, -0.4420,  1.5781,  ..., -1.9981,  0.8899,  0.4250]],

         [[ 0.3419,  1.7789,  0.3598,  ..., -0.2396, -0.5313, -2.3594],
          [ 0.1099,  0.2703,  0.0379,  ..., -1.0330,  0.2319, -0.7118],
          [-0.8576,  0.3835,  0.1941,  ..., -0.4465, -0.2445, -1.3141],
          ...,
          [ 0.9101,  0.0835,  0.1603,  ..., -0.1463, -1.1543,  0.1213],
          [ 0.7945, -0.2397,  0.9480,  ..., -0.9665,  0.1957, -0.1343],
          [ 0.6488, -0.0114,  1.4170,  ..., -1.4343,  0.2728, -0.3779]]]],
       device='cuda:0'), 'next_latents': tensor([[[[ 0.2663,  1.2585,  0.2900,  ..., -0.3512, -0.9914, -2.0887],
          [-0.0569,  0.2884,  0.2081,  ..., -1.0520, -0.0070, -1.1591],
          [-0.6952,  0.1688,  0.1247,  ..., -0.3106, -0.4505, -1.0528],
          ...,
          [ 0.6973,  0.1471,  0.0984,  ..., -0.3613, -1.0175, -0.4393],
          [ 0.5498,  0.0393,  0.7371,  ..., -0.6799, -0.5461, -0.5738],
          [ 0.2343, -0.0391,  0.9409,  ..., -1.4798, -0.3425, -0.8196]],

         [[ 0.1528,  2.1250,  0.0403,  ...,  0.2182,  0.1919, -3.0349],
          [-0.1685,  0.8578, -0.7008,  ..., -1.3787,  0.8812, -0.8446],
          [-1.8650,  0.6566, -0.4611,  ..., -0.1353, -0.6820, -1.6257],
          ...,
          [ 1.3464, -0.0157, -0.1057,  ...,  0.0083, -1.6834,  1.1149],
          [ 0.7052, -0.6253,  1.5157,  ..., -1.6735,  1.0792,  0.8521],
          [ 0.8007, -0.4364,  1.6168,  ..., -2.0444,  0.9834,  0.5041]],

         [[ 0.2350,  2.0688,  0.0970,  ...,  0.2158,  0.2495, -2.9093],
          [-0.2127,  0.8057, -0.6211,  ..., -1.3435,  0.8837, -0.8254],
          [-1.8323,  0.6708, -0.4005,  ..., -0.2597, -0.6627, -1.5818],
          ...,
          [ 1.3695,  0.0187, -0.1004,  ...,  0.0169, -1.6307,  1.0316],
          [ 0.7552, -0.5190,  1.5085,  ..., -1.6485,  1.0266,  0.8439],
          [ 0.7919, -0.4420,  1.5781,  ..., -1.9981,  0.8899,  0.4250]],

         ...,

         [[ 0.3040,  1.8875,  0.2994,  ..., -0.0109, -0.0290, -2.7519],
          [-0.1197,  0.6266, -0.1586,  ..., -1.3236,  0.5855, -0.7586],
          [-1.2479,  0.5218, -0.3625,  ..., -0.2352, -0.4892, -1.3604],
          ...,
          [ 1.2754,  0.1321,  0.0287,  ...,  0.0237, -1.5227,  0.6372],
          [ 0.6045, -0.4394,  1.3178,  ..., -1.4083,  0.5620,  0.4969],
          [ 0.7403, -0.0562,  1.6067,  ..., -1.8101,  0.5293,  0.0178]],

         [[ 0.1622,  2.0395,  0.0748,  ...,  0.2112,  0.1997, -2.9643],
          [-0.2384,  0.7537, -0.4948,  ..., -1.3183,  0.8209, -0.8812],
          [-1.8245,  0.6431, -0.3719,  ..., -0.2938, -0.5898, -1.5186],
          ...,
          [ 1.3982,  0.0656, -0.1095,  ...,  0.0446, -1.6347,  1.0969],
          [ 0.6821, -0.4732,  1.5047,  ..., -1.6057,  1.0253,  0.9079],
          [ 0.7854, -0.3406,  1.5805,  ..., -1.9031,  0.7635,  0.3657]],

         [[ 0.3646,  1.5657,  0.2889,  ..., -0.3116, -0.6338, -2.2098],
          [ 0.0547,  0.3400,  0.1262,  ..., -0.9814,  0.1881, -0.8448],
          [-0.7660,  0.3479,  0.1502,  ..., -0.4045, -0.3750, -1.2002],
          ...,
          [ 0.8154,  0.1466,  0.1145,  ..., -0.2817, -1.1435,  0.0833],
          [ 0.7117, -0.1690,  0.9565,  ..., -0.8087,  0.0462, -0.1302],
          [ 0.6296,  0.0032,  1.2252,  ..., -1.2557,  0.1362, -0.4680]]]],
       device='cuda:0'), 'condition_latents': tensor([[[ 1.3438,  0.3164,  0.3145,  ..., -2.2344, -2.5781, -2.5469],
         [ 0.3750,  0.3926, -0.1514,  ..., -2.2188, -2.4688, -2.4531],
         [ 0.3945,  0.3945, -0.0830,  ..., -2.2188, -2.4531, -2.4531],
         ...,
         [-0.5039, -0.5000, -0.0903,  ..., -2.0156, -1.9297, -1.9297],
         [-0.5000, -0.4824, -0.0879,  ..., -2.0469, -1.9297, -1.9531],
         [-0.5625,  0.7188, -0.0083,  ..., -2.2812, -1.8984, -2.0938]]],
       device='cuda:0', dtype=torch.bfloat16), 'condition_ids': tensor([[ 0.0000,  0.3125,  0.3125],
        [ 0.0000,  0.3125,  1.9375],
        [ 0.0000,  0.3125,  3.5625],
        ...,
        [ 0.0000, 50.7500, 47.5000],
        [ 0.0000, 50.7500, 49.0000],
        [ 0.0000, 50.7500, 50.7500]], device='cuda:0', dtype=torch.bfloat16), 'condition_type_ids': tensor([[1.],
        [1.],
        [1.],
        ...,
        [4.],
        [4.],
        [4.]], device='cuda:0', dtype=torch.bfloat16), 'log_probs': tensor([[-0.4990, -0.4994, -0.5021, -0.5004, -0.5003, -0.4986, -0.4989, -0.4990,
         -0.4973, -0.4968, -0.5005, -0.4987, -0.5009, -0.5029, -0.5022]],
       device='cuda:0'), 'image_ids': tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  1.],
        [ 0.,  0.,  2.],
        ...,
        [ 0., 51., 49.],
        [ 0., 51., 50.],
        [ 0., 51., 51.]], device='cuda:0', dtype=torch.bfloat16), 'text_ids': tensor([[0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16), 'encoder_hidden_states': tensor([[[-0.2734,  0.1982,  0.0242,  ..., -0.0454,  0.0024,  0.0488],
         [-0.1138, -0.0068,  0.0938,  ..., -0.3438,  0.0116,  0.1289],
         [ 0.0811,  0.1602,  0.1543,  ..., -0.0962,  0.1475,  0.1855],
         ...,
         [ 0.0591, -0.0116,  0.0486,  ..., -0.0007, -0.0488, -0.0184],
         [ 0.0845, -0.0245, -0.0103,  ..., -0.1211, -0.0752,  0.0223],
         [ 0.0062,  0.0170, -0.0131,  ..., -0.0048, -0.0183,  0.0086]]],
       device='cuda:0', dtype=torch.bfloat16), 'pooled_prompt_embeds': tensor([[ 4.5312e-01, -4.1016e-01, -2.7539e-01,  9.8828e-01,  6.6895e-02,
         -3.2031e-01, -1.0156e-01,  1.2188e+00,  2.6758e-01, -2.2949e-02,
          1.1426e-01, -1.2422e+00, -1.4688e+00,  6.3477e-03, -1.2891e+00,
         -8.3496e-02,  8.3984e-01,  1.3984e+00,  3.8574e-02, -2.2852e-01,
          5.7812e-01,  1.2305e-01,  1.0400e-01, -2.2266e-01, -2.9907e-02,
         -5.1172e-01, -5.5078e-01,  7.0703e-01, -8.9453e-01, -5.0391e-01,
         -7.0312e-01,  1.2969e+00, -2.9102e-01, -1.0078e+00,  1.4688e+00,
          4.1992e-01, -2.4844e+00,  1.3672e+00,  2.9785e-02, -3.6133e-02,
          8.2031e-01, -3.5645e-02,  6.2988e-02,  2.1562e+00, -2.0938e+00,
         -2.9688e-01,  8.9062e-01,  1.0859e+00, -1.3125e+00,  1.4062e-01,
          6.5625e-01, -1.0703e+00, -6.0938e-01,  4.6875e-01,  5.3125e-01,
          2.1875e-01,  5.9766e-01, -2.0938e+00,  1.3379e-01, -2.6250e+00,
          2.3926e-01, -4.8438e-01, -5.7812e-01,  2.4688e+00,  1.0059e-01,
          2.4658e-02, -9.7266e-01,  1.9434e-01,  7.5391e-01,  5.7812e-01,
         -2.7344e-01, -1.0703e+00,  1.3906e+00,  5.9766e-01,  9.4727e-02,
          1.1094e+00,  2.4121e-01,  4.6289e-01, -8.8501e-03, -5.5078e-01,
         -5.0000e-01, -1.5527e-01,  6.4062e-01, -1.4746e-01,  5.4688e-01,
          5.9766e-01,  1.4688e+00,  4.9414e-01,  2.7148e-01, -2.0156e+00,
         -2.2168e-01, -5.0781e-01, -4.1748e-02,  8.7891e-01,  1.8203e+00,
          6.4844e-01,  4.9561e-02,  2.6367e-01, -2.6758e-01, -9.3359e-01,
          1.1094e+00,  1.8652e-01,  1.4609e+00,  1.5332e-01,  2.2559e-01,
         -6.0156e-01,  2.1973e-01,  9.6484e-01,  5.6250e-01,  4.8242e-01,
         -9.9609e-02, -9.0625e-01,  1.7422e+00,  1.9609e+00, -8.0859e-01,
          3.1445e-01, -9.7266e-01, -9.5703e-01, -5.6641e-01,  4.1016e-01,
         -3.8281e-01,  1.0781e+00, -3.1250e-01,  7.1289e-02,  2.1562e+00,
         -1.4219e+00, -5.4688e-01,  1.0312e+00, -7.2656e-01, -2.7734e-01,
         -1.4355e-01, -8.9844e-02, -1.1230e-01,  9.6875e-01,  3.1641e-01,
         -1.3984e+00,  1.7383e-01, -2.0703e-01,  1.4551e-01,  2.0625e+00,
          8.7891e-02, -1.4922e+00,  2.5391e-01, -4.4336e-01, -1.9409e-02,
         -1.6484e+00,  7.1875e-01,  7.6953e-01,  5.3125e-01, -3.7109e-01,
         -9.8438e-01,  8.3594e-01, -6.4062e-01,  5.7422e-01,  8.1641e-01,
         -8.6719e-01, -1.7090e-01, -4.4922e-01,  1.3203e+00,  4.4922e-01,
         -1.0078e+00,  8.2422e-01, -2.6172e-01, -4.5117e-01,  1.9141e-01,
         -9.7656e-02, -2.3145e-01,  1.1719e+00, -3.9844e-01, -8.8672e-01,
         -1.2756e-02,  6.2500e-01, -8.6670e-03,  1.3750e+00, -1.2812e+00,
          8.2812e-01,  7.9688e-01, -7.4609e-01, -1.2969e+00, -2.3730e-01,
         -1.4258e-01,  1.7456e-02,  3.4180e-02,  3.8477e-01,  4.3359e-01,
         -1.7578e+00,  7.9102e-02,  2.1289e-01,  8.6328e-01, -2.3145e-01,
          6.6406e-02,  6.3965e-02,  3.6914e-01, -1.3203e+00,  6.8750e-01,
         -7.5391e-01,  9.3359e-01,  7.7344e-01,  6.8359e-01,  1.3125e+00,
         -9.2969e-01, -1.3906e+00, -5.3467e-02, -8.0078e-01,  1.5938e+00,
         -5.3906e-01, -9.5312e-01, -9.7266e-01, -2.5977e-01,  1.3281e+00,
          3.8672e-01,  5.1172e-01, -1.2344e+00,  1.1562e+00, -6.3672e-01,
          7.2656e-01, -4.4434e-02, -5.1953e-01, -6.3281e-01, -3.8867e-01,
          3.3789e-01, -4.8633e-01, -2.7344e+00, -1.2891e+00, -3.2812e-01,
         -7.0312e-01, -3.0664e-01, -8.3594e-01, -1.1875e+00, -7.7344e-01,
         -5.3516e-01, -1.4062e-01, -2.1191e-01,  1.2817e-02,  1.1172e+00,
         -2.1094e-01,  1.5527e-01, -2.7930e-01, -6.5430e-02,  1.2500e+00,
         -3.1445e-01, -2.4062e+00,  1.5000e+00, -1.1475e-01, -2.1719e+00,
         -3.7891e-01,  2.2070e-01,  9.0625e-01, -2.6562e-01,  9.1406e-01,
          1.3125e+00, -1.1250e+00, -3.4375e-01,  1.3379e-01, -4.5703e-01,
          5.5847e-03, -1.3379e-01,  7.6172e-02, -1.2891e-01,  7.1484e-01,
         -1.5527e-01, -1.9336e-01, -6.3281e-01, -1.8359e-01, -2.3906e+00,
         -4.0820e-01,  7.8516e-01, -2.5469e+00,  5.0000e-01,  1.9434e-01,
         -1.1797e+00, -1.1094e+00, -5.3906e-01,  1.5156e+00, -9.9219e-01,
         -1.6797e-01,  1.4258e-01, -7.1777e-02, -2.4609e-01, -4.5508e-01,
         -1.0312e+00, -2.8281e+00, -5.1172e-01, -1.0391e+00,  1.3203e+00,
          1.3379e-01,  2.4805e-01, -1.3574e-01, -1.3203e+00,  6.8750e-01,
         -2.2812e+00,  5.5859e-01, -1.3359e+00,  1.8555e-01, -9.1016e-01,
         -8.1641e-01, -7.0801e-02, -1.6641e+00, -3.7891e-01, -8.8672e-01,
         -4.3164e-01,  1.0859e+00,  1.8516e+00, -8.4961e-02,  4.9609e-01,
          1.0703e+00, -1.4609e+00,  1.1875e+00, -1.2578e+00, -4.7656e-01,
         -2.2969e+00, -3.3203e-01,  4.1406e-01,  5.3125e-01, -1.7422e+00,
          5.4297e-01, -1.5527e-01, -8.4473e-02,  5.3516e-01, -2.4261e-03,
         -9.4922e-01, -8.9062e-01,  1.6094e+00,  1.3906e+00,  1.3750e+00,
         -1.2969e+00,  3.1641e-01, -7.8613e-02, -5.7422e-01, -2.6367e-01,
          1.6641e+00,  9.1016e-01, -1.2500e-01, -1.4688e+00,  2.5000e+00,
         -2.4316e-01,  8.1641e-01, -3.7891e-01,  1.3184e-01, -5.4297e-01,
         -1.9531e+00,  1.1797e+00, -1.5430e-01,  8.8672e-01,  7.9688e-01,
          1.1797e+00,  1.6875e+00,  8.6914e-02, -1.6562e+00, -1.1250e+00,
          1.0078e+00,  2.9541e-02,  1.3047e+00,  1.3000e-02, -9.9219e-01,
          7.6562e-01, -5.3516e-01, -1.4766e+00, -8.3203e-01, -2.7734e-01,
         -1.4648e-01, -4.4141e-01,  2.9492e-01, -5.3906e-01, -1.4141e+00,
         -9.8438e-01,  5.8203e-01, -4.5703e-01, -1.7812e+00, -1.6235e-02,
          6.6797e-01,  5.5859e-01, -7.0312e-01, -1.3984e+00, -1.2109e-01,
          6.9141e-01, -1.8750e+00,  4.5312e-01, -6.5918e-02, -1.0352e-01,
          1.1953e+00, -3.9453e-01,  1.6562e+00, -6.3672e-01, -9.1016e-01,
          1.5703e+00,  2.4512e-01, -8.5938e-02,  2.1387e-01,  1.4141e+00,
          1.7969e+00,  1.1523e-01,  1.0938e+00,  3.2617e-01, -7.3438e-01,
          3.4180e-01,  9.0820e-02, -1.6094e+00, -1.4531e+00,  1.3867e-01,
          2.4531e+00,  4.9805e-01, -9.6680e-02, -1.2109e+00,  6.1035e-02,
          8.9844e-02, -1.4219e+00, -6.8359e-02, -4.6289e-01, -8.5938e-01,
         -1.0156e+00,  1.8359e-01, -5.2344e-01, -1.3203e+00,  1.5000e+00,
         -4.7656e-01,  1.7969e+00, -1.1406e+00,  2.1484e-02, -5.4297e-01,
         -8.8672e-01, -1.5000e+00, -4.9805e-01, -1.1572e-01, -8.8867e-02,
          1.0059e-01, -1.0645e-01, -7.3828e-01,  7.8906e-01,  2.3804e-02,
          5.9375e-01, -6.5234e-01, -2.6953e-01, -7.3438e-01, -8.5547e-01,
         -8.0469e-01, -1.1328e+00, -1.2422e+00,  2.7466e-02,  8.0078e-01,
          2.3281e+00, -1.0078e+00, -5.1562e-01, -9.5000e+00,  2.4805e-01,
         -1.3594e+00, -1.2109e+00,  5.5078e-01, -5.0781e-01, -1.5469e+00,
          7.1875e-01,  7.1484e-01,  2.2949e-02, -1.0078e+00,  6.5625e-01,
         -6.7188e-01,  4.7266e-01, -1.4453e+00,  1.6504e-01,  2.9883e-01,
          1.5469e+00, -5.0391e-01, -3.8281e-01, -8.6328e-01, -2.1094e+00,
         -2.1875e+00,  1.3750e+00, -1.4531e+00, -7.4219e-01,  2.0020e-01,
         -7.9297e-01,  1.1016e+00, -2.0000e+00, -1.4922e+00,  1.9238e-01,
         -6.0938e-01,  4.0625e-01,  2.6094e+00, -8.1250e-01,  2.0156e+00,
         -1.5938e+00, -6.5234e-01, -1.4922e+00, -4.1250e+00, -9.8828e-01,
         -1.7266e+00, -1.2695e-01,  1.3672e+00,  9.0332e-02, -9.4531e-01,
          4.0625e-01, -3.8086e-01, -1.4453e+00, -1.0703e+00, -2.2461e-01,
          6.9922e-01,  5.3125e-01,  5.5078e-01,  6.7969e-01, -2.2500e+00,
          3.8281e-01,  4.4336e-01,  2.9297e-01, -3.9648e-01, -1.9824e-01,
          4.2969e-02,  7.7734e-01,  6.4453e-01,  6.9922e-01, -5.0781e-01,
         -1.2891e+00,  1.4453e+00,  8.0469e-01, -1.2656e+00, -1.2969e+00,
         -2.1191e-01,  1.3672e+00, -3.2031e-01, -1.2734e+00,  1.3750e+00,
          5.0781e-01, -4.9805e-01, -7.8516e-01, -1.4141e+00, -1.5781e+00,
         -1.2188e+00,  1.6406e-01, -4.9609e-01,  9.4922e-01,  7.1484e-01,
         -6.3281e-01, -7.7344e-01,  7.9590e-02,  2.0117e-01,  1.0547e+00,
          1.1172e+00, -5.3906e-01,  7.3828e-01,  8.1641e-01,  6.1328e-01,
         -3.3594e-01, -1.3203e+00,  1.9727e-01, -8.0078e-01, -6.5234e-01,
          1.3828e+00, -1.6719e+00, -1.0156e+00, -1.0400e-01,  7.3438e-01,
         -4.1016e-01,  8.5156e-01, -2.9102e-01, -2.2500e+00, -4.1406e-01,
          1.7285e-01, -1.2031e+00,  9.6484e-01,  5.1953e-01, -8.9453e-01,
         -2.4219e-01, -4.4062e+00, -1.5547e+00,  1.2266e+00,  3.9291e-04,
         -4.9023e-01,  2.8516e-01, -2.0781e+00, -3.8477e-01, -3.3936e-02,
         -5.5859e-01,  1.5820e-01,  8.2031e-01, -1.6797e+00,  1.5234e+00,
          6.9922e-01, -6.9531e-01, -1.8438e+00, -5.1514e-02, -2.5625e+00,
          4.7070e-01,  1.3770e-01,  4.5117e-01, -3.7695e-01,  1.8750e+00,
         -6.4453e-02, -5.0391e-01, -1.9531e+00, -6.9922e-01,  2.8906e+00,
         -6.1523e-02,  7.3438e-01, -6.8359e-01,  3.4180e-02, -2.2705e-02,
         -1.0156e+00,  1.9062e+00,  2.8125e-01, -3.8867e-01,  6.7969e-01,
         -1.2891e+00, -3.9062e-01, -3.6719e-01, -9.4922e-01, -6.6016e-01,
         -1.1719e-01,  9.6484e-01,  1.3047e+00, -4.5508e-01, -4.5654e-02,
          2.9492e-01,  1.1797e+00, -1.1035e-01,  4.7852e-01,  6.9141e-01,
          3.9453e-01, -2.2949e-01,  6.5625e-01, -8.4766e-01, -1.0938e+00,
         -1.9043e-01,  8.2422e-01,  3.6133e-01,  7.6953e-01, -2.7148e-01,
          7.7148e-02,  4.5703e-01,  1.9375e+00, -4.1992e-01,  2.7344e-01,
          8.4375e-01,  2.0996e-01, -1.6641e+00, -6.2500e-01,  2.4902e-01,
         -1.0703e+00, -1.9922e-01,  6.2891e-01, -1.0469e+00, -4.2969e-01,
          1.4531e+00, -1.1016e+00,  4.0527e-02, -1.4688e+00,  1.7344e+00,
         -4.0234e-01, -1.0547e+00, -5.0391e-01, -1.2500e+00, -1.3438e+00,
          9.7656e-03, -8.5547e-01,  1.2422e+00, -6.2109e-01,  5.2344e-01,
          4.5654e-02,  2.5586e-01, -2.2827e-02,  1.0938e+00,  1.0312e+00,
          6.3281e-01,  2.8125e-01, -9.9219e-01,  4.3750e-01,  8.0859e-01,
         -2.9297e-01, -1.1875e+00, -1.0859e+00,  2.1680e-01, -3.2422e-01,
         -8.1250e-01,  3.2227e-02, -5.0391e-01,  9.8828e-01, -7.8906e-01,
         -9.4531e-01, -1.7188e+00,  1.2695e-02, -1.9434e-01,  1.6641e+00,
          1.1641e+00,  1.4844e+00,  1.8652e-01,  1.5859e+00,  7.3438e-01,
         -9.4141e-01, -9.3359e-01, -1.3047e+00, -8.9844e-01,  9.1309e-02,
         -1.9141e+00,  2.9297e-01, -2.0625e+00,  1.1172e+00,  4.0625e-01,
         -7.2266e-01,  5.7812e-01, -2.3125e+00, -6.4062e-01, -3.0078e-01,
         -2.2812e+00,  1.4766e+00, -5.5859e-01,  6.9141e-01,  4.3164e-01,
         -1.6719e+00, -5.7031e-01, -2.2812e+00,  7.1289e-02, -3.3008e-01,
         -3.8086e-01,  2.5391e-01, -3.3984e-01, -1.0859e+00,  4.5703e-01,
          1.6172e+00,  1.1953e+00, -8.2422e-01, -1.5547e+00,  1.3203e+00,
          8.4766e-01, -3.8477e-01,  4.2578e-01,  1.6699e-01,  4.2969e-01,
         -1.5156e+00,  3.5312e+00,  6.4062e-01,  3.2715e-02,  6.8750e-01,
          3.0664e-01, -2.0312e+00, -7.6562e-01,  2.8809e-02, -1.0156e+00,
         -8.7109e-01,  4.5703e-01, -2.2188e+00, -5.3906e-01, -3.7842e-02,
         -2.5146e-02, -1.1328e+00, -7.8516e-01,  1.0938e+00, -1.6016e+00,
          1.0234e+00,  1.2969e+00,  3.1250e-01, -1.0938e+00,  8.5547e-01,
         -1.2578e+00, -4.6631e-02,  1.6895e-01, -4.3555e-01, -3.9648e-01,
         -7.3828e-01,  2.2461e-01, -5.4688e-01, -3.3203e-01,  7.2656e-01,
         -6.4844e-01,  3.5352e-01,  7.8125e-01, -5.8984e-01,  2.2363e-01,
         -1.1406e+00, -1.1865e-01,  5.9375e-01]], device='cuda:0',
       dtype=torch.bfloat16)}
Traceback (most recent call last):
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1451, in <module>
    main(args)
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1097, in main
    loss, grad_norm = train_one_step(
  File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 865, in train_one_step
    sample["final_advantages"],
KeyError: 'final_advantages'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1451, in <module>
[rank0]:     main(args)
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 1097, in main
[rank0]:     loss, grad_norm = train_one_step(
[rank0]:   File "/root/autodl-tmp/DiffusionGRPO/src/train_grpo_flux.py", line 865, in train_one_step
[rank0]:     sample["final_advantages"],
[rank0]: KeyError: 'final_advantages'
